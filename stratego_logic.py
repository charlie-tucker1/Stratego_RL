# -*- coding: utf-8 -*-
"""Stratego_logic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b9C-bQKX7IWlFIbC5E1bubE82vO2sMyA
"""

import random as random
import numpy as np
import gymnasium as gym
from gymnasium import spaces

# Define all pieces
class Piece():
  ''' parent class for all pieces, including flags and bombs
      types can take = flag, bomb, soldier '''
  def __init__(self, color, rank, type):
    self.color = color
    self.rank = rank
    self.type = type

class Flag(Piece):
  def __init__(self, color):
    super().__init__(color, rank=0, type='flag')

class Bomb(Piece):
  def __init__(self, color):
    super().__init__(color, rank=0, type='bomb')
class Spy(Piece):
  def __init__(self, color):
    super().__init__(color, rank=1, type='soldier')
class Scout(Piece):
  def __init__(self, color):
    super().__init__(color, rank=2, type='soldier')
class Miner(Piece):
  def __init__(self, color):
    super().__init__(color, rank=3, type='soldier')
class Sergeant(Piece):
  def __init__(self, color):
    super().__init__(color, rank=4, type='soldier')
class Lieutenant(Piece):
  def __init__(self, color):
    super().__init__(color, rank=5, type='soldier')
class Captain(Piece):
  def __init__(self, color):
    super().__init__(color, rank=6, type='soldier')
class Major(Piece):
  def __init__(self, color):
    super().__init__(color, rank=7, type='soldier')
class Colonel(Piece):
  def __init__(self, color):
    super().__init__(color, rank=8, type='soldier')
class General(Piece):
  def __init__(self, color):
    super().__init__(color, rank=9, type='soldier')
class Marshal(Piece):
  def __init__(self, color):
    super().__init__(color, rank=10, type='soldier')

# Class contains the unmasked board state with the core operations
LAKES = [(4,2), (4,3), (5,2), (5,3), (4,6), (4,7), (5,6), (5,7)]

class BoardStateUnmasked:
    """
    Ground truth board state. Only the Game class should touch this.
    Contains full information about all pieces.
    """

    def __init__(self):
        self.grid = [[None for _ in range(10)] for _ in range(10)]
        self.captured = {'red': [], 'blue': []}
        self.pieces_to_place = {
            'red': self._starting_pieces('red'),
            'blue': self._starting_pieces('blue')
        }


    # SETUP


    def _starting_pieces(self, color):
        """40 pieces per player"""
        return [
            Flag(color),
            *[Bomb(color) for _ in range(6)],
            Spy(color),
            *[Scout(color) for _ in range(8)],
            *[Miner(color) for _ in range(5)],
            *[Sergeant(color) for _ in range(4)],
            *[Lieutenant(color) for _ in range(4)],
            *[Captain(color) for _ in range(4)],
            *[Major(color) for _ in range(3)],
            *[Colonel(color) for _ in range(2)],
            General(color),
            Marshal(color),
        ]

    def get_placement_zone(self, color):
        """Red gets rows 6-9, Blue gets rows 0-3"""
        if color == 'red':
            return [(r, c) for r in range(6, 10) for c in range(10)]
        else:
            return [(r, c) for r in range(0, 4) for c in range(10)]

    def get_legal_placements(self, color):
        """Returns list of (piece_index, row, col)"""
        placements = []
        zone = self.get_placement_zone(color)
        empty_cells = [(r, c) for r, c in zone if self.grid[r][c] is None]

        for idx, piece in enumerate(self.pieces_to_place[color]):
            for r, c in empty_cells:
                placements.append((idx, r, c))

        return placements

    def place_piece(self, color, piece_index, row, col):
        """Place a piece during setup"""
        piece = self.pieces_to_place[color].pop(piece_index)
        self.grid[row][col] = piece


    # PIECE COUNTS


    @property
    def red_piececount(self):
        return sum(1 for row in self.grid for p in row if p and p.color == 'red')

    @property
    def blue_piececount(self):
        return sum(1 for row in self.grid for p in row if p and p.color == 'blue')


    # FLAG STATUS


    def redflag_captured(self):
        return any(p.type == 'flag' and p.color == 'red' for p in self.captured['red'])

    def blueflag_captured(self):
        return any(p.type == 'flag' and p.color == 'blue' for p in self.captured['blue'])


    # MOVEMENT


    def is_valid_cell(self, row, col):
        """Check if cell is on board and not a lake"""
        if row < 0 or row > 9 or col < 0 or col > 9:
            return False
        if (row, col) in LAKES:
            return False
        return True

    def get_legal_moves(self, color):
        """Returns list of (from_row, from_col, to_row, to_col)"""
        moves = []
        directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]  # up, down, left, right

        for r in range(10):
            for c in range(10):
                piece = self.grid[r][c]
                if piece is None or piece.color != color:
                    continue
                if piece.type in ['flag', 'bomb']:  # immovable
                    continue

                if piece.rank == 2:  # Scout moves multiple squares
                    for dr, dc in directions:
                        for dist in range(1, 10):
                            nr, nc = r + dr * dist, c + dc * dist
                            if not self.is_valid_cell(nr, nc):
                                break
                            target = self.grid[nr][nc]
                            if target is None:
                                moves.append((r, c, nr, nc))
                            elif target.color != color:
                                moves.append((r, c, nr, nc))
                                break  # can't jump over enemy
                            else:
                                break  # blocked by own piece
                else:  # Normal piece moves 1 square
                    for dr, dc in directions:
                        nr, nc = r + dr, c + dc
                        if not self.is_valid_cell(nr, nc):
                            continue
                        target = self.grid[nr][nc]
                        if target is None or target.color != color:
                            moves.append((r, c, nr, nc))

        return moves

    def move_piece(self, from_row, from_col, to_row, to_col):
        """Move piece with no combat"""
        piece = self.grid[from_row][from_col]
        self.grid[from_row][from_col] = None
        self.grid[to_row][to_col] = piece


    # COMBAT
    #------------------------------------------------------------------

    def remove_piece(self, row, col):
        """Remove piece from board and add to captured list"""
        piece = self.grid[row][col]
        if piece:
            self.captured[piece.color].append(piece)
            self.grid[row][col] = None
        return piece

    def resolve_combat(self, attacker_pos, defender_pos):
        """
        Resolve combat between two pieces.
        Returns: 'attacker', 'defender', or 'both' (mutual destruction)
        """
        ar, ac = attacker_pos
        dr, dc = defender_pos
        attacker = self.grid[ar][ac]
        defender = self.grid[dr][dc]

        # Flag capture - attacker always wins
        if defender.type == 'flag':
            self.remove_piece(dr, dc)
            self.move_piece(ar, ac, dr, dc)
            return 'attacker'

        # Bomb - only miner survives
        if defender.type == 'bomb':
            if attacker.rank == 3:  # Miner defuses
                self.remove_piece(dr, dc)
                self.move_piece(ar, ac, dr, dc)
                return 'attacker'
            else:
                self.remove_piece(ar, ac)
                self.remove_piece(dr, dc)  # bomb also removed after exploding
                return 'defender'

        # Spy kills Marshal only when attacking
        if attacker.rank == 1 and defender.rank == 10:
            self.remove_piece(dr, dc)
            self.move_piece(ar, ac, dr, dc)
            return 'attacker'

        # Standard combat - higher rank wins
        if attacker.rank > defender.rank:
            self.remove_piece(dr, dc)
            self.move_piece(ar, ac, dr, dc)
            return 'attacker'
        elif defender.rank > attacker.rank:
            self.remove_piece(ar, ac)
            return 'defender'
        else:  # Equal rank - both die
            self.remove_piece(ar, ac)
            self.remove_piece(dr, dc)
            return 'both'

#Evaluate board state function, returns a value, higher = better for red, lower = better for blue
def evaluate(bsu):
    if bsu.redflag_captured():
        return 1000
    if bsu.blueflag_captured():
        return -1000
    return (bsu.red_piececount - bsu.blue_piececount) * 10

class BoardStateMasked:
    """
    What one player can actually see.
    Converts to tensor observation for RL agent.
    """

    def __init__(self, bsu, viewer_color, revealed=None):
        self.viewer = viewer_color
        self.revealed = revealed or set()
        self.grid = [[None for _ in range(10)] for _ in range(10)]
        self._build_from(bsu)

    def _build_from(self, bsu):
        for r in range(10):
            for c in range(10):
                piece = bsu.grid[r][c]
                if piece is None:
                    self.grid[r][c] = None
                elif piece.color == self.viewer:
                    # Full info on own pieces
                    self.grid[r][c] = {
                        'color': piece.color,
                        'rank': piece.rank,
                        'type': piece.type,
                        'known': True
                    }
                else:
                    # Enemy piece
                    if (r, c) in self.revealed:
                        self.grid[r][c] = {
                            'color': piece.color,
                            'rank': piece.rank,
                            'type': piece.type,
                            'known': True
                        }
                    else:
                        self.grid[r][c] = {
                            'color': piece.color,
                            'rank': None,
                            'type': None,
                            'known': False
                        }

    def to_observation(self):
        """
        Convert to numpy array for RL agent.

        Channels (27 total):
          0: your flag
          1: your bombs
          2-11: your soldiers (rank 1-10: spy, scout, miner...marshal)
          12: known enemy flag
          13: known enemy bombs
          14-23: known enemy soldiers (rank 1-10)
          24: unknown enemy pieces
          25: empty cells
          26: lakes

        Shape: (27, 10, 10)
        """
        obs = np.zeros((27, 10, 10), dtype=np.float32)

        for r in range(10):
            for c in range(10):
                # Lakes
                if (r, c) in LAKES:
                    obs[26, r, c] = 1
                    continue

                cell = self.grid[r][c]

                # Empty cell
                if cell is None:
                    obs[25, r, c] = 1
                    continue

                # Your pieces (full info)
                if cell['color'] == self.viewer:
                    if cell['type'] == 'flag':
                        obs[0, r, c] = 1
                    elif cell['type'] == 'bomb':
                        obs[1, r, c] = 1
                    else:  # soldier
                        obs[cell['rank'] + 1, r, c] = 1  # rank 1 -> channel 2, etc.

                # Enemy pieces
                else:
                    if cell['known']:
                        # Known enemy
                        if cell['type'] == 'flag':
                            obs[12, r, c] = 1
                        elif cell['type'] == 'bomb':
                            obs[13, r, c] = 1
                        else:
                            obs[cell['rank'] + 13, r, c] = 1  # rank 1 -> channel 14
                    else:
                        # Unknown enemy
                        obs[24, r, c] = 1

        return obs

    def render_known(self):
        """Debug: show what this player sees"""
        print(f"\n{self.viewer}'s view:")
        print("  0 1 2 3 4 5 6 7 8 9")

        symbols = {
            'flag': 'F', 'bomb': 'B',
            1: 'S', 2: '2', 3: '3', 4: '4', 5: '5',
            6: '6', 7: '7', 8: '8', 9: '9', 10: 'M'
        }

        for r in range(10):
            row_str = f"{r} "
            for c in range(10):
                if (r, c) in LAKES:
                    row_str += "~ "
                elif self.grid[r][c] is None:
                    row_str += ". "
                else:
                    cell = self.grid[r][c]
                    if cell['known']:
                        sym = symbols.get(cell['rank'], symbols.get(cell['type'], '?'))
                        if cell['color'] == 'blue':
                            sym = sym.lower()
                        row_str += sym + " "
                    else:
                        row_str += "? "  # unknown enemy
            print(row_str)

class Game:
    """
    Main game orchestrator. Holds ground truth (bsu) and provides
    masked views to each player. Also handles turn management.
    """

    def __init__(self, random_placement=True):
        # Ground truth
        self.bsu = BoardStateUnmasked()

        # What each player can see - rebuilt after every action
        self.red_view = None
        self.blue_view = None

        # Turn management
        self.current_player = 'red'  # red moves first
        self.phase = 'placement'     # 'placement' or 'movement'
        self.turn_count = 0

        # Track revealed pieces - survives across turns
        self.revealed = {'red': set(), 'blue': set()}  # positions known to each player

        # Game state
        self.done = False
        self.winner = None

        # Initialize
        if random_placement:
            self._random_setup()
            self.phase = 'movement'

        self._rebuild_views()

    # SETUP PHASE

    def _random_setup(self):
        """Quick random placement for both sides"""
        for color in ['red', 'blue']:
            zone = self.bsu.get_placement_zone(color)
            random.shuffle(zone)
            for i, piece in enumerate(self.bsu.pieces_to_place[color]):
                r, c = zone[i]
                self.bsu.grid[r][c] = piece
            self.bsu.pieces_to_place[color] = []

    def get_legal_placements(self):
        """During placement phase, what can current player do?"""
        return self.bsu.get_legal_placements(self.current_player)

    def do_placement(self, piece_index, row, col):
        """Place a piece during setup phase"""
        if self.phase != 'placement':
            raise ValueError("Not in placement phase")

        self.bsu.place_piece(self.current_player, piece_index, row, col)

        # Check if this player is done placing
        if not self.bsu.pieces_to_place[self.current_player]:
            self._switch_player()

            # Check if both players are done
            if not self.bsu.pieces_to_place[self.current_player]:
                self.phase = 'movement'
                self.current_player = 'red'  # red moves first in movement

        self._rebuild_views()


    # MOVEMENT PHASE


    def get_legal_moves(self):
        """During movement phase, what can current player do?"""
        return self.bsu.get_legal_moves(self.current_player)

    def do_move(self, from_row, from_col, to_row, to_col):
        """Execute a move during movement phase"""
        if self.phase != 'movement':
            raise ValueError("Not in movement phase")
        if self.done:
            raise ValueError("Game is over")

        from_pos = (from_row, from_col)
        to_pos = (to_row, to_col)

        target = self.bsu.grid[to_row][to_col]

        if target is not None:
            # COMBAT - reveal both pieces to both players
            self._reveal_to_both(from_pos)
            self._reveal_to_both(to_pos)

            # Resolve the fight
            result = self.bsu.resolve_combat(from_pos, to_pos)

            # Check for flag capture (game over)
            self._check_win_condition()
        else:
            # Simple move, no combat
            self.bsu.move_piece(from_row, from_col, to_row, to_col)

            # Update revealed tracking (piece moved to new position)
            self._update_revealed_position(from_pos, to_pos)

        self.turn_count += 1
        self._switch_player()
        self._rebuild_views()

        # Check if next player has any legal moves
        if not self.done and not self.get_legal_moves():
            self.done = True
            self.winner = self._other_player(self.current_player)


    # OBSERVATION - agent specific


    def get_observation(self, color):
        """
        Returns the observation for one player.
        """
        if color == 'red':
            return self.red_view.to_observation()
        else:
            return self.blue_view.to_observation()

    def get_action_mask(self, color):
        """
        Returns a binary mask of legal actions.
        For PettingZoo/PufferLib, flatten this.
        """
        if self.phase == 'placement':
            return self._placement_action_mask(color)
        else:
            return self._movement_action_mask(color)

    def _movement_action_mask(self, color):
        """
        Action space for movement: 10 * 10 * 4 = 400 actions
        (from_cell) * (direction: up/down/left/right)

        LIMITATION: Scouts can move multiple squares in Stratego, but this
        implementation only encodes single-step moves (dr/dc = -1, 0, 1).
        Scout multi-square moves are filtered out to keep action space simple.
        This means scouts effectively move like regular pieces in this version.

        Simplified version: action = from_cell * 4 + direction
        """
        mask = np.zeros(400, dtype=np.float32)

        legal_moves = self.bsu.get_legal_moves(color)

        for from_r, from_c, to_r, to_c in legal_moves:
            # Determine direction
            dr, dc = to_r - from_r, to_c - from_c

            # For scouts moving multiple squares, we encode as repeated single steps
            # Simple version: only encode the immediate target
            if abs(dr) <= 1 and abs(dc) <= 1:
                direction = self._direction_to_index(dr, dc)
                action_idx = (from_r * 10 + from_c) * 4 + direction
                mask[action_idx] = 1

        return mask

    def _direction_to_index(self, dr, dc):
        """Convert delta to direction index"""
        if dr == -1: return 0  # up
        if dr == 1: return 1   # down
        if dc == -1: return 2  # left
        if dc == 1: return 3   # right

    def action_to_move(self, action):
        """Convert flat action index back to (from_r, from_c, to_r, to_c)"""
        direction = action % 4
        cell = action // 4
        from_r, from_c = cell // 10, cell % 10

        deltas = [(-1, 0), (1, 0), (0, -1), (0, 1)]
        dr, dc = deltas[direction]

        return (from_r, from_c, from_r + dr, from_c + dc)


    # INTERNAL HELPERS

    def _switch_player(self):
        self.current_player = self._other_player(self.current_player)

    def _other_player(self, color):
        return 'blue' if color == 'red' else 'red'

    def _reveal_to_both(self, pos):
        """After combat, both players know what was at this position"""
        self.revealed['red'].add(pos)
        self.revealed['blue'].add(pos)

    def _update_revealed_position(self, old_pos, new_pos):
        """When a piece moves, update reveal tracking"""
        for color in ['red', 'blue']:
            if old_pos in self.revealed[color]:
                self.revealed[color].remove(old_pos)
                self.revealed[color].add(new_pos)

    def _rebuild_views(self):
        """Rebuild what each player can see"""
        self.red_view = BoardStateMasked(
            self.bsu,
            viewer_color='red',
            revealed=self.revealed['red']
        )
        self.blue_view = BoardStateMasked(
            self.bsu,
            viewer_color='blue',
            revealed=self.revealed['blue']
        )

    def _check_win_condition(self):
        """Check if game is over"""
        if self.bsu.redflag_captured():
            self.done = True
            self.winner = 'blue'
        elif self.bsu.blueflag_captured():
            self.done = True
            self.winner = 'red'


    # INFO / DEBUG

    def get_reward(self, color):
        """
        Reward signal for RL.
        Only non-zero at game end, maybe we'll add shaping later.
        """
        if not self.done:
            return 0
        if self.winner == color:
            return 1
        elif self.winner is None:
            return 0  # draw
        else:
            return -1

    def render(self):
        """Debug print of the board"""
        symbols = {
            'flag': 'F', 'bomb': 'B',
            1: 'S', 2: '2', 3: '3', 4: '4', 5: '5',
            6: '6', 7: '7', 8: '8', 9: '9', 10: 'M'
        }

        print(f"\nTurn {self.turn_count} - {self.current_player}'s move")
        print("  0 1 2 3 4 5 6 7 8 9")

        for r in range(10):
            row_str = f"{r} "
            for c in range(10):
                if (r, c) in LAKES:
                    row_str += "~ "
                elif self.bsu.grid[r][c] is None:
                    row_str += ". "
                else:
                    piece = self.bsu.grid[r][c]
                    sym = symbols.get(piece.rank, symbols.get(piece.type, '?'))
                    # Lowercase for blue, uppercase for red
                    if piece.color == 'blue':
                        sym = sym.lower()
                    row_str += sym + " "
            print(row_str)


class ScriptedAgent:
    """
    Simple heuristic bot. Not smart, but enough to beat random.
    """

    def __init__(self, color):
        self.color = color
        self.enemy = 'blue' if color == 'red' else 'red'
        self.forward = -1 if color == 'red' else 1  # red moves up, blue moves down

    def select_move(self, game):
        """Pick a move using simple heuristics"""
        moves = game.bsu.get_legal_moves(self.color)
        if not moves:
            return None

        scored_moves = []
        for move in moves:
            score = self._score_move(game, move)
            scored_moves.append((score, move))

        # Pick best move (with some randomness for ties)
        scored_moves.sort(key=lambda x: -x[0])
        best_score = scored_moves[0][0]
        best_moves = [m for s, m in scored_moves if s == best_score]

        return random.choice(best_moves)

    def _score_move(self, game, move):
        """Score a move. Higher = better."""
        from_r, from_c, to_r, to_c = move
        piece = game.bsu.grid[from_r][from_c]
        target = game.bsu.grid[to_r][to_c]

        score = 0

        # Attacking is good
        if target is not None:
            score += self._attack_score(piece, target, game)

        # Moving forward is good
        if (to_r - from_r) == self.forward:
            score += 5

        # Don't move flag protectors early
        if piece.rank >= 8 and game.turn_count < 50:
            score -= 3

        # Scouts should explore
        if piece.rank == 2:
            score += 2

        # Don't move bombs or flag (they can't, but just in case)
        if piece.type in ['bomb', 'flag']:
            score -= 1000

        return score

    def _attack_score(self, attacker, defender, game):
        """
        Score an attack. Positive = good
        We don't know enemy rank unless revealed, so we guess
        """
        # If we know the defender's rank (revealed)
        if hasattr(defender, 'rank'):
            known_rank = defender.rank
        else:
            known_rank = None

        # Check if this piece was revealed to us
        defender_pos = None
        for r in range(10):
            for c in range(10):
                if game.bsu.grid[r][c] is defender:
                    defender_pos = (r, c)
                    break

        if defender_pos and defender_pos in game.revealed[self.color]:
            # We know what it is
            if defender.type == 'flag':
                return 1000  # WIN
            if defender.type == 'bomb':
                if attacker.rank == 3:  # miner
                    return 50
                else:
                    return -50  # don't suicide into bomb

            # Standard combat
            if attacker.rank > defender.rank:
                return 30 + defender.rank  # win, bonus for high-rank kills
            elif attacker.rank == defender.rank:
                return -10  # trade, meh
            else:
                return -30  # we lose

        else:
            # Unknown enemy - use heuristics
            # Low-rank pieces should probe
            if attacker.rank <= 3:
                return 10  # scouts/miners are expendable
            elif attacker.rank <= 5:
                return 5   # mid-tier, ok to attack
            else:
                return -5  # high-value, don't risk blindly

class StrategoEnv(gym.Env):
    """
    Single-agent env: you play red, scripted bot plays blue.

    Action Space: 3600 discrete actions
    - Encodes: (position, direction, distance)
    - position: 100 board cells (0-99)
    - direction: 4 directions (up, down, left, right)
    - distance: 9 distances (1-9 squares)
    - Scouts can use full distance range, other pieces limited to distance 1

    Reward Schema:
    - Material: +/- piece rank when captured/lost
    - Strategic: +2 for spy killing marshal, +1 for miner defusing bomb
    - Territorial: +0.1 for moving deeper into enemy territory
    - Terminal: +100 for winning, -100 for losing

    KNOWN LIMITATIONS:
    - Placement phase is auto-randomized (not part of action space)
    """

    metadata = {"render_modes": ["human", "ansi"]}

    def __init__(self, render_mode=None):
        super().__init__()
        self.render_mode = render_mode

        # Observation: (27, 10, 10) tensor
        self.observation_space = spaces.Box(
            low=0, high=1, shape=(27, 10, 10), dtype=np.float32
        )

        # Action: 3600 discrete actions (100 cells * 4 directions * 9 distances)
        # Action encoding: action = position * 36 + direction * 9 + (distance - 1)
        self.action_space = spaces.Discrete(3600)

        self.game = None
        self.bot = None

        # Piece values for reward shaping
        self.piece_values = {
            0: 0,   # Flag/Bomb
            1: 1,   # Spy
            2: 2,   # Scout
            3: 3,   # Miner
            4: 4,   # Sergeant
            5: 5,   # Lieutenant
            6: 6,   # Captain
            7: 7,   # Major
            8: 8,   # Colonel
            9: 9,   # General
            10: 10  # Marshal
        }

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)

        self.game = Game(random_placement=True)
        self.bot = ScriptedAgent('blue')

        obs = self.game.get_observation('red')
        info = {"action_mask": self._get_action_mask()}

        return obs, info

    def step(self, action):
        # Execute red's move
        move = self._action_to_move(action)

        # Validate move is legal
        legal_moves = self.game.get_legal_moves()
        if move not in legal_moves:
            # Invalid action - penalize and skip
            obs = self.game.get_observation('red')
            return obs, -0.1, False, False, {"action_mask": self._get_action_mask()}

        # Track state before move for reward calculation
        from_r, from_c, to_r, to_c = move
        red_captured_before = len(self.game.bsu.captured['red'])
        blue_captured_before = len(self.game.bsu.captured['blue'])

        # Get piece info for territorial reward
        moving_piece = self.game.bsu.grid[from_r][from_c]

        # Execute move
        self.game.do_move(*move)

        # Calculate reward from red's move
        reward = self._calculate_step_reward(
            'red', from_r, to_r,
            red_captured_before, blue_captured_before
        )

        # Check if game ended after red's move
        if self.game.done:
            obs = self.game.get_observation('red')
            terminal_reward = 100.0 if self.game.winner == 'red' else -100.0
            return obs, reward + terminal_reward, True, False, {}

        # Bot plays blue
        bot_move = self.bot.select_move(self.game)
        if bot_move:
            # Track state before bot move
            red_captured_before = len(self.game.bsu.captured['red'])
            blue_captured_before = len(self.game.bsu.captured['blue'])

            bot_from_r, bot_from_c, bot_to_r, bot_to_c = bot_move
            self.game.do_move(*bot_move)

            # Subtract reward from bot's move (negative for us)
            bot_reward = self._calculate_step_reward(
                'blue', bot_from_r, bot_to_r,
                red_captured_before, blue_captured_before
            )
            reward -= bot_reward  # Bot's gain is our loss

        # Check if game ended after blue's move
        if self.game.done:
            obs = self.game.get_observation('red')
            terminal_reward = 100.0 if self.game.winner == 'red' else -100.0
            return obs, reward + terminal_reward, True, False, {}

        # Game continues
        obs = self.game.get_observation('red')
        truncated = self.game.turn_count > 1000  # safety limit

        return obs, reward, False, truncated, {"action_mask": self._get_action_mask()}

    def _calculate_step_reward(self, color, from_row, to_row, red_cap_before, blue_cap_before):
        """Calculate reward for a single move"""
        reward = 0.0

        # Material rewards: check what pieces were captured
        red_captured_after = len(self.game.bsu.captured['red'])
        blue_captured_after = len(self.game.bsu.captured['blue'])

        if color == 'red':
            # Red's perspective
            # Positive: captured blue pieces
            if blue_captured_after > blue_cap_before:
                captured_piece = self.game.bsu.captured['blue'][-1]
                material_reward = self.piece_values.get(captured_piece.rank, 0)
                reward += material_reward

                # Strategic bonuses
                # Check if this was spy killing marshal
                if captured_piece.rank == 10:  # Marshal captured
                    # Check if attacker was spy (need to look at what moved)
                    # Since piece already moved, check if it's rank 1 at destination
                    to_piece = self.game.bsu.grid[to_row][:]
                    for piece in to_piece:
                        if piece and piece.color == 'red' and piece.rank == 1:
                            reward += 2.0  # Spy killed marshal bonus
                            break

                # Check if miner defused bomb
                if captured_piece.type == 'bomb':
                    reward += 1.0  # Miner defused bomb bonus

            # Negative: lost red pieces
            if red_captured_after > red_cap_before:
                lost_piece = self.game.bsu.captured['red'][-1]
                material_penalty = self.piece_values.get(lost_piece.rank, 0)
                reward -= material_penalty

            # Territorial reward: moving deeper into enemy territory
            # Red moves up (decreasing row numbers), enemy territory is rows 0-3
            if to_row < from_row and to_row < 4:  # Moved up into enemy territory
                reward += 0.1

        else:  # color == 'blue'
            # Blue's perspective (same logic, inverted)
            if red_captured_after > red_cap_before:
                captured_piece = self.game.bsu.captured['red'][-1]
                material_reward = self.piece_values.get(captured_piece.rank, 0)
                reward += material_reward

                # Strategic bonuses for blue
                if captured_piece.rank == 10:  # Marshal captured
                    to_piece = self.game.bsu.grid[to_row][:]
                    for piece in to_piece:
                        if piece and piece.color == 'blue' and piece.rank == 1:
                            reward += 2.0
                            break

                if captured_piece.type == 'bomb':
                    reward += 1.0

            if blue_captured_after > blue_cap_before:
                lost_piece = self.game.bsu.captured['blue'][-1]
                material_penalty = self.piece_values.get(lost_piece.rank, 0)
                reward -= material_penalty

            # Territorial reward: blue moves down (increasing row), enemy territory is rows 6-9
            if to_row > from_row and to_row > 5:  # Moved down into enemy territory
                reward += 0.1

        return reward

    def _get_action_mask(self):
        """Return binary mask of legal actions"""
        mask = np.zeros(3600, dtype=np.float32)
        legal_moves = self.game.get_legal_moves()

        for from_r, from_c, to_r, to_c in legal_moves:
            dr, dc = to_r - from_r, to_c - from_c

            # Calculate direction and distance
            if dr != 0 and dc != 0:
                continue  # Diagonal moves not allowed in Stratego

            if dr != 0:
                direction = 0 if dr < 0 else 1  # up or down
                distance = abs(dr)
            elif dc != 0:
                direction = 2 if dc < 0 else 3  # left or right
                distance = abs(dc)
            else:
                continue  # No movement

            # Encode action: action = position * 36 + direction * 9 + (distance - 1)
            position = from_r * 10 + from_c
            action_idx = position * 36 + direction * 9 + (distance - 1)
            mask[action_idx] = 1

        return mask

    def _direction_to_index(self, dr, dc):
        if dr == -1: return 0  # up
        if dr == 1: return 1   # down
        if dc == -1: return 2  # left
        if dc == 1: return 3   # right

    def _action_to_move(self, action):
        """Decode action to (from_r, from_c, to_r, to_c)"""
        # action = position * 36 + direction * 9 + (distance - 1)
        position = action // 36
        remainder = action % 36
        direction = remainder // 9
        distance = (remainder % 9) + 1

        from_r, from_c = position // 10, position % 10

        deltas = [(-1, 0), (1, 0), (0, -1), (0, 1)]
        dr, dc = deltas[direction]

        to_r = from_r + dr * distance
        to_c = from_c + dc * distance

        return (from_r, from_c, to_r, to_c)

    def render(self):
        if self.render_mode == "human":
            self.game.render()


if __name__ == '__main__':
    # Test the environment
    env = StrategoEnv(render_mode="human")
    obs, info = env.reset()

    print(f"Observation shape: {obs.shape}")
    print(f"Legal actions: {np.sum(info['action_mask'])}")

    # Random agent vs scripted bot
    for _ in range(100):
        mask = info.get("action_mask", np.ones(400))
        legal_actions = np.where(mask == 1)[0]

        if len(legal_actions) == 0:
            break

        action = np.random.choice(legal_actions)
        obs, reward, done, truncated, info = env.step(action)

        if done or truncated:
            print(f"Game over! Reward: {reward}")
            break

    env.render()

    env = StrategoEnv()
    obs, info = env.reset()

    print(f"Initial legal actions: {np.sum(info['action_mask'])}")
    # Should be ~30-50, not 5

    # Also verify the game's legal moves directly
    print(f"Game legal moves: {len(env.game.get_legal_moves())}")